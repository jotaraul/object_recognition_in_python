{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Object Recognition in Python Notebook!\n",
    "\n",
    "This module is part of the set of scripts within object_recognition_in_python. This notebook was released by J.R. Ruiz-Sarmiento, and is publicly available at:\n",
    "\n",
    "https://github.com/jotaraul/object_recognition_in_python\n",
    "\n",
    "under the GNUv3 license. Their goal is to show some directions for the utilization of tools writen in Python, like pandas, seaborn or scikit-learn, for the design of object recognition systems.\n",
    "    \n",
    "Hope you enjoy the experience and, above all, learn ;)\n",
    "\n",
    "First, we will start loading the needed Python modules:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# General imports\n",
    "import numpy as np\n",
    "# For managing and ploting data\n",
    "import pandas\n",
    "import scipy\n",
    "import seaborn\n",
    "import time\n",
    "from bisect import bisect\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "# scikit-learn imports\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, \\\n",
    "    GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Tutorial imports\n",
    "import scripts.utils_notebook as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to configure different options like the dataset, the features (variables) to work with, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "# [GENERAL CONFIGURATION]\n",
    "\n",
    "config[\"dataset_file\"] = './datasets/robot_at_home.csv'\n",
    "config[\"balance_dataset\"] = True\n",
    "config[\"vbles_to_work_with\"] = [ 'PLANARITY','SCATTER','LINEARITY','MINHEIGHT','MAXHEIGHT','CENTROID_X','CENTROID_Y','CENTROID_Z',\n",
    "                       'VOLUME','BIGGESTAREA','ORIENTATION','HUEMEAN','SATMEAN','VALMEAN','HUESTDV','SATSTDV','VALSTDV',\n",
    "                       'HUEHIST0','HUEHIST1','HUEHIST2','HUEHIST3','HUEHIST4','VALHIST0','VALHIST1','VALHIST2',\n",
    "                       'VALHIST3','VALHIST4','SATHIST0','SATHIST1','SATHIST2','SATHIST3','SATHIST4' ]\n",
    "config[\"gt_vble\"] = 'OBJECTCATEGORY'\n",
    "config[\"n_object_categories\"] = 15\n",
    "\n",
    "# [DESCRIPTIVE ANALYSIS CONFIGURATION]\n",
    "\n",
    "config[\"graphical_representation\"] = 'boxplot'\n",
    "config[\"n_discrete_values\"] = 2\n",
    "\n",
    "# [PRE-PROCESSING CONFIGURATION]\n",
    "\n",
    "config[\"standarized_features\"] = True\n",
    "\n",
    "# [MODEL TESTING CONFIGURATION]\n",
    "\n",
    "config[\"models_to_work_with\"] = ['Logistic','SVM','KNeighbors','DecisionTree','RandomForest','ExtraTrees','GaussianNaiveBayes']\n",
    "config[\"cross_validation_n_iterations\"] = 10\n",
    "config[\"cross_validation_n_folds\"] = 4\n",
    "config[\"show_confuion_matrix\"] = False\n",
    "config[\"confusion_matrix_show_method\"] = 'RandomForest'\n",
    "\n",
    "# [VISUALIZATION OPTIONS]\n",
    "#title_font = {'fontname': 'Arial', 'size': '21', 'color': 'black', 'weight': 'normal', 'verticalalignment': 'bottom'}\n",
    "config[\"title_font\"] = {'size': '21', 'color': 'black', 'weight': 'normal', 'verticalalignment': 'bottom'}\n",
    "#axis_font = {'fontname': 'Arial', 'size': '20'}\n",
    "config[\"axis_font\"] = {'size': '20'}\n",
    "config[\"ticks_size\"] = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step: data managament and analysis\n",
    "\n",
    "Now, we load the dataset containing characterized objects and perform some analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go! Load the dataset\n",
    "data = pandas.read_csv(config[\"dataset_file\"], low_memory=False)\n",
    "\n",
    "# print some information about the dataset\n",
    "print (\"[Working the the '\" + config[\"dataset_file\"].split('/')[-1] + \"' dataset!]\")\n",
    "print (\"Info: \")\n",
    "print (\"Number of observations within the dataset: \" + str(len(data)))  # number of observations (rows)\n",
    "print (\"Number of variables                      : \" + str(len(data.columns)))  # number of variables (columns)\n",
    "\n",
    "# upper-case all DataFrame column names\n",
    "data.columns = map(str.upper, data.columns)\n",
    "\n",
    "for vble in config[\"vbles_to_work_with\"]:\n",
    "    # setting variables you will be working with to numeric\n",
    "    data[vble] = pandas.to_numeric(data[vble], errors=\"coerce\")\n",
    "\n",
    "# And the ground truth one to categorical\n",
    "data[config[\"gt_vble\"]] = data[config[\"gt_vble\"]].astype('category')\n",
    "\n",
    "# Get entries corresponding with the selected object categories (config[\"n_object_categories\"] most appearing)\n",
    "sub_data = pandas.value_counts(data[config[\"gt_vble\"]], sort=True)\n",
    "print (\"Number of observations with values       : \" + str(np.sum(sub_data)))\n",
    "print ('Number of different categories           : ' + str(sub_data.size))\n",
    "print (\"\\nNumber of objects per category in the dataset:\")\n",
    "print (sub_data)\n",
    "data = data[data['OBJECTCATEGORY'].isin(sub_data.index[0:config[\"n_object_categories\"]])]\n",
    "data['OBJECTCATEGORY'] = data['OBJECTCATEGORY'].cat.remove_unused_categories()\n",
    "#data[config[\"gt_vble\"] = data[config[\"gt_vble\"].replace({'upper_cabinet': 'ucabinet'}) # only for Robot@Home dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphically show the instances distribution in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATION \n",
    "# Visually show the most appearing categories\n",
    "utils.plot_instances_distribution(data, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"balance_dataset\"]:\n",
    "    g = data.groupby('OBJECTCATEGORY')\n",
    "    data = g.apply(lambda x: x.sample(g.size().min())).reset_index(drop=True)\n",
    "\n",
    "    c2 = pandas.value_counts(data[config[\"gt_vble\"]], sort=True)\n",
    "    print (\"Number of observations with values: \" + str(np.sum(c2)))\n",
    "    print (c2)\n",
    "    data = data[data['OBJECTCATEGORY'].isin(c2.index[0:config[\"n_object_categories\"]])]\n",
    "    data['OBJECTCATEGORY'] = data['OBJECTCATEGORY'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe predictors\n",
    "for vble in config[\"vbles_to_work_with\"]:\n",
    "    print (data[vble].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATION\n",
    "#\n",
    "utils.plot_variables_description(data, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn predictors into categorical vbles for chi-square test\n",
    "utils.turn_vbles_to_categorical(data, config[\"vbles_to_work_with\"], config)\n",
    "chi2 = [[], []]\n",
    "\n",
    "for vble in config[\"vbles_to_work_with\"]:\n",
    "    ct1 = pandas.crosstab(data[config[\"gt_vble\"]], data[vble + '_C'])\n",
    "    print (str(vble) + '_C: chi-square value, p value, expected counts')\n",
    "    cs1 = scipy.stats.chi2_contingency(ct1)\n",
    "    chi2[0].append(cs1[0])\n",
    "    chi2[1].append(vble)\n",
    "    print (cs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATION \n",
    "utils.plot_chi_square_values(chi2, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second step: preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"standarized_features\"]:\n",
    "    # Standardize variables to have mean=0 and sd=1\n",
    "    for vble in config[\"vbles_to_work_with\"]:\n",
    "        data[vble] = preprocessing.scale(data[vble].astype('float64'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third step: model fitting and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare predictor and ground truth variables\n",
    "data_X = data[config[\"vbles_to_work_with\"]]\n",
    "data_y = data[config[\"gt_vble\"]]\n",
    "\n",
    "# Compute the performance of each model\n",
    "models = [{'name': 'Logistic', 'clf': linear_model.LogisticRegression(), 'statistics': utils.statistics()},\n",
    "          #{'name': 'DecisionTree', 'clf': tree.DecisionTreeClassifier(), 'statistics': utils.statistics()},\n",
    "          #{'name': 'RandomForest', 'clf': RandomForestClassifier(), 'statistics': utils.statistics()},\n",
    "          #{'name': 'ExtraTrees', 'clf': ExtraTreesClassifier(), 'statistics': utils.statistics()},\n",
    "          {'name': 'SVM', 'clf': svm.SVC(kernel='linear'), 'statistics': utils.statistics()},\n",
    "          #{'name': 'KNeighbors', 'clf': KNeighborsClassifier(), 'statistics': utils.statistics()},\n",
    "          {'name': 'MLP', 'clf': MLPClassifier(alpha=1), 'statistics': utils.statistics()},\n",
    "          {'name': 'GaussianProcess', 'clf': GaussianProcessClassifier(1.0 * RBF(1.0)), 'statistics': utils.statistics()},\n",
    "          {'name': 'GaussianNaiveBayes', 'clf': GaussianNB(), 'statistics': utils.statistics()},\n",
    "          {'name': 'QDA', 'clf': QuadraticDiscriminantAnalysis(), 'statistics': utils.statistics()},\n",
    "          {'name': 'AdaBoost', 'clf': AdaBoostClassifier(), 'statistics': utils.statistics()},\n",
    "          {'name': 'GradientBoosting', 'clf': GradientBoostingClassifier(), 'statistics': utils.statistics()}\n",
    "          ]\n",
    "\n",
    "accumulated_cnf_matrix = np.zeros(shape=(config[\"n_object_categories\"], config[\"n_object_categories\"]), dtype=int)\n",
    "\n",
    "print ('Obtaining metrics for..',)\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    if model['name'] in config[\"models_to_work_with\"]:\n",
    "\n",
    "        seaborn.set_palette(seaborn.color_palette(\"husl\", len(config[\"models_to_work_with\"])))\n",
    "\n",
    "        print (model['name'] + '..',)\n",
    "\n",
    "        for try_i in range(0, config[\"cross_validation_n_iterations\"]):\n",
    "\n",
    "            test_size = 1. / config[\"cross_validation_n_folds\"]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=test_size)\n",
    "            model['clf'].fit(X_train, y_train)\n",
    "            y_pred = model['clf'].predict(X_test)\n",
    "\n",
    "            model['statistics'].accuracy.append(metrics.accuracy_score(y_test, y_pred))\n",
    "            model['statistics'].macro_precision.append(metrics.precision_score(y_test, y_pred, average='macro'))\n",
    "            model['statistics'].macro_recall.append(metrics.recall_score(y_test, y_pred, average='macro'))\n",
    "            model['statistics'].f1_score.append(metrics.f1_score(y_test, y_pred, average='micro'))\n",
    "\n",
    "            model['statistics'].partial_accuracy.append(np.mean(model['statistics'].accuracy))\n",
    "            model['statistics'].partial_macro_precision.append(np.mean(model['statistics'].macro_precision))\n",
    "            model['statistics'].partial_f1_score.append(np.mean(model['statistics'].f1_score))\n",
    "\n",
    "            if config[\"confusion_matrix_show_method\"]:\n",
    "                cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                accumulated_cnf_matrix = np.add(accumulated_cnf_matrix, cnf_matrix)\n",
    "\n",
    "        utils.plot_partial_cross_validation_results(range=range(1, config[\"cross_validation_n_iterations\"] + 1),\n",
    "                                                    metric=model['statistics'].partial_f1_score,\n",
    "                                                    label=model['name'])\n",
    "\n",
    "# VISUALIZATION\n",
    "utils.plot_cross_validation(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATION\n",
    "\n",
    "# Show confusion matrix\n",
    "utils.plot_confusion_matrix(accumulated_cnf_matrix, classes=sorted(c2.index[0:config[\"n_object_categories\"]]),\n",
    "                                normalize=False,\n",
    "                                title='Normalized confusion matrix')\n",
    "utils.plot_confusion_matrix(accumulated_cnf_matrix, classes=sorted(c2.index[0:config[\"n_object_categories\"]]),\n",
    "                                normalize=True,\n",
    "                                title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATION\n",
    "# Show the models performance using a different sets of features\n",
    "utils.plot_performance_with_sets_of_features(models, chi2, data, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
